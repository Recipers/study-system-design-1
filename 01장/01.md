# 1. 사용자 수에 따른 규모 확장성

## 단일 서버

한 대의 서버로 운영하는 시스템이다.

![alt text](<image (4).png>)
## 데이터베이스



데이터베이스가 추가된 형태다. 웹/모바일 트래픽 처리 용도와 데이터베이스 용도로 책임이 분리된다. 이는 다음과 같은 이점을 가진다.

- 웹 서버의 부하 분산으로 인해 성능이 향상된다.
- 책임 분리로 인해 유연성과 오류 대응성이 향상된다.(데이터베이스를 간단하게 교체할 수 있으며, 오류를 빠르게 찾을 수 있음)

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/a6a9b136-b602-4f91-8acb-8f62c3fbcf0c/image.png)

### 데이터베이스의 선택: 관계형 vs 비관계형

낮은 응답 지연시간, 비정형 데이터, 직렬화 가능, 데이터의 양 많음 이 조건이라면 비관계형 데이터베이스가 옳다.

RDBMS의 경우, ACID 원칙 준수, 무결성, 정규화, 접근성이라는 장점을 가지지만, 낮은 확장성, 경직된 스키마, 복잡도에 따른 성능 저하라는 단점을 가진다.

반면 NoSQL은 NoSQL의 다양성, 확장성, 데이터 형식의 자유도라는 장점을 가진다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/2daa3d34-d56c-4fc3-8d82-4f1dc576453e/image.png)

https://www.mongodb.com/resources/compare/relational-vs-non-relational-databases

## 수직적 확장과 수평적 확장



서버로 유입되는 트랙픽의 양이 적을 대는 수직적 확장이 좋은 선택이다.

수직적 확장은 다음과 같은 단점이 있다.

- 확장에 한계가 있음
- 장애에 대한 자동 복구 방안, 다중화 방안을 제시하지 않음. 서버에 장애가 발상하면 서비스 중단

### 로드밸런서

로드밸런서는 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다. 로드밸런서는 다음과 같은 기능을 한다.

- 부하 분산을 통한 성능을 향상시킨다. 웹 서버에 전송되는 트래픽을 골고루 분배한다.
- 보안성을 제공한다. 사용자는 공개 IP 주소를 통해 로드밸런서에 접근하며, 로드밸런서는 웹 서버의 사설 IP 주소를 통해 접근한다.
- 장애 복구 문제를 해결하며 가용성을 늘려준다. 하나의 웹 서버가 고장난 경우, 다른 웹 서버로 자동으로 연결시켜준다.
- 확장성을 높여준다. 웹 서버의 대수를 자유롭게 조절할 수 있다.
- 부하 분산 알고리즘이 어떤게 있나 ? 대표적으로 라운드 로빈 방식이 존재한다. 이는 서버로 들어온 요청을 순서대로 돌아가며 배정하는 방식이다.

데이터베이스도 다중화를 지원한다. 보통 주-부 서버 관계를 설정하며, 데이터 원본은 주 서버, 사본은 부 서버에 저장한다.

쓰기 연산은 주 서버에서만 지원한다. 부 서버는 그 사본을 전달받으며, 읽기 연산만을 지원한다.

대부분의 서비스는 읽기 연산이 많기 때문에 부 서버 데이터베이스의 수가 상대적으로 많다. 이러한 구조는 다음과 같은 이점을 제공한다.

- 더 나은 성능 : 부 서버 DB의 다중화로 읽기 연산이 병렬로 처리될 수 있다.
- 안정성 : 데이터베이스 서버가 일부 손상돼도 데이터가 보존된다.
- 가용성 : 데이터를 여러 지역에 복제해 둠으로써, 장애가 발생해도 다른 DB로 대체할 수 있다.

하나의 주, 부 서버를 가지는 경우, 각 서버가 다운되면 다른 서버가 이를 대체한다.

여러 부서버를 가지는 경우, 주 서버가 다운되어도, 다른 부 서버가 주 서버를 대신할 수 있다. 반대로 하나의 부 서버가 다운되는 경우, 다른 여러 부 서버가 이를 대체해준다.

실제 서비스 환경에서는 더 복잡한 상황이 발생하는데, 부 서버에 보관된 데이터가 최신 상태가 아닐 수 있다. (주 서버와 부 서버가 실시간으로 통신하지 않기 때문이다) 없는 데이터는 복구 스크립트를 돌려서 추가, 다중 마스터, 원형 다중화 방식을 도입하면 해결할 수 있다.

주, 부 서버가 다운되었을 때, 순간적으로 발생하는 데이터 유실을 어떻게 막을 수 있을까?

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/33d09d48-50ee-4063-8b9e-34e2ab898440/image.png)

### DB 다중화 상황에서 서버의 동기화 방식

그렇다면 주 서버와 부 서버는 서로 어떤 주기로 동기화하나 ? 주 서버가 CUD를 진행한 뒤, 부 서버로 동기화 한다. 이 때 동기식 복제, 반동기식 복제, 비동기식 복제로 나뉜다.

동기식 복제는 주 서버가 CUD에 대한 트랜잭션을 커밋할 때, 모든 부 서버가 동일한 데이터를 복제할 때 까지 기다렸다가 커밋하는 방식이다. 즉, 주 서버가 부 서버의 동기화가 완료될 때 까지 기다린다는 의미다.

동기식 복제는 복제 데이터가 일관적이다는 장점이 있지만, 성능 저하 문제가 생기며, 부 서버가 모종의 이유로 response하지 않는다면, 주 서버는 이를 끊임 없이 기다려야 한다.

비동기식 복제는 주 서버가 부 서버의 동기화 완료를 기다리지 않는 방식이다. 빠른 지연시간을 보장할 수 있다는 장점이 있다. 그러나 복제 지연이 발생할 수 있으며, 복제 중 주 서버에 장애가 발생할 경우 데이터가 유실될 수 있다.

이에 따라 반동기식 복제를 생각할 수 있다. 주 서버의 트랜잭션 처리 중, 최소 한 대 이상의 부 서버가 동기화 완료 플래그를 보내면 트랜잭션을 종료하는 방식이다. 비동기식 복제보다 성능은 떨어지지만, 적어도 하나 이상은 동기화했기 때문에 안전성이 높아진다는 장점이 있다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/2082c966-f701-4b7b-9eec-81fb675aa827/image.png)

다음은 로드밸런서와 데이터베이스 다중화를 고려한 설계다. 

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/82a8b192-1c23-4401-9958-cc18cb41dab5/image.png)

응답 시간을 개선할 차례다. 캐시와 CDN을 이용해 개선할 수 있다.

## 캐시



캐시는 값비싼 연산 결과 혹은 자주 참조되는 데이터를 메모리 안에 두고 빠르게 처리할 수 있도록 하는 저장소다. 웹페이지의 속도는 데이터베이스 호출 빈도에 크게 영향을 받는데, 캐시는 이를 완화해준다.

캐시를 사용할 땐, 다음과 같은 사항을 고려해야 한다.

- 캐시는 데이터 변경이 적고 조회가 빈번하게 일어나면 고려할만 하다.
- 캐시는 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 옳지 않다.
- 캐시 만료 정책 생성은 중요하다. 너무 짧으면 DB를 자주 읽게 되며, 너무 길면 원본과 차이가 발생할 수 있다.
- 캐시의 일관성을 지키는 것은 어려운 일이다. 데이터 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우, 일관성이 깨질 수 있다. 그렇다면 어떻게 이를 처리하나? → 캐시 전략을 사용하면 성능과 타협하여 정합성을 지킬 수 있다.
- 캐시의 장애 대응도 고려해야 한다. 하나의 캐시 서버를 두는 경우 단일 장애 지점(SPOF)이 될 수 있다. 따라서 캐시 서버도 여러 지역에 걸쳐 분산해야 한다. SPOF는 해당 지점에서 장애가 일어날 경우 전체 시스템의 동작을 중단시킴을 의미한다.
- 캐시 메모리의 크기도 중요하다. 메모리가 작을 경우, 접근 패턴에 따라서 데이터가 너무 자주 갱신되는 문제가 발생한다. 이를 캐시 메모리의 과할당으로 해결할 수 있다. 이렇게 되면 캐시에 보관될 데이터가 갑자기 늘어났을 때 생기는 문제를 방지할 수 있다.
- 캐시의 데이터 방출 정책도 고려해야 한다. 캐시가 꽉 찼을 때, 어떤 데이터를 내보니야 하는가? 가장 널리 쓰이는 것은 LRU 정책이다. LFU, FIFO 등 존재한다.

### 캐시 전략

캐시는 크기가 한정적이기 때문에 어느 종류의 데이터를 저장할지, 얼만큼 저장할지, 얼마나 오랫동안 저장할 지에 대한 전략을 숙지할 필요가 있다. 캐시는 읽기 전략과 쓰기 전략이 존재한다.

[읽기 전략 - Look Aside 패턴]

데이터를 찾을 때 캐시에 저장된 데이터가 있는지 우선적으로 확인하는 전략이다. 데이터가 없다면 DB에서 조회한다. DB에서 조회된 데이터는 캐시에 저장된다.

캐시 미스가 발생할 경우, 서버 → 캐시 → DB → 서버 → 캐시 순서를 거친다.

반복적인 읽기가 많은 호출에 적합하다.

캐시 장애에 대비할 수 있다. 그러나 장애 발생 시, 순간적으로 DB에 많은 부하가 발생할 수 있다.

정합성 문제가 발생할 수 있다. 어떻게 해결하지? DB가 변경되면 연결된 캐시 데이터도 변경해줘야 하나 ?

단건 호출 빈도가 높은 서비스보다 반복적으로 동일 쿼리를 수행하는 서비스에 적합하다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/61f54d59-f3a2-42c7-b228-59c58faf6574/image.png)

[읽기 전략 - Read Through 패턴]

캐시에서만 데이터를 읽어오는 전략이다. 캐시에 데이터가 없으면 캐시가 직접 DB를 확인한 뒤 캐시에 저장한다. 즉, DB 동기화 주체가 캐시가 되는 것이다.

캐시 미스가 발생할 경우, 서버 → 캐시 → DB → 캐시 → 서버 순서를 거치기 때문에 Look Aside 패턴보다 상대적으로 느리다. 

서버가 DB에 직접 영향을 주려면 캐시를 반드시 거쳐야 하기 때문에 정합성 문제를 해결할 수 있다.

캐시가 SPOF가 되기 때문에 오류 발생 시 서비스 전체가 다운될 수 있다. 이는 Replication 또는 Cluster로 구성하여 해결할 수 있다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/86f51828-0679-460d-aa7e-4b998a6e84ca/image.png)

[쓰기 전략 - Write Back 패턴]

데이터를 저장할 때 캐시에 모아두었다가 특정 시점마다 DB로 쓰는 방식이다.

캐시에 모아두었다가 DB에 쓰기 때문에 쓰기 쿼리 비용을 줄일 수 있다. 또한 캐시를 반드시 거치기 때문에 정합성이 유지된다.

그러나 자주 사용하지 않는 불필요한 리소스를 저장할 수 있으며, 캐시에 오류가 발생하면 데이터 영구 손실이 발생한다. 반대로 DB에 장애가 발생하더라도 지속적인 서비스를 제공할 수 있다. (쓰기가 일어나 캐시에 저장되지만 잘 사용하지 않는 데이터를 불필요한 리소스라고 칭한다)

쓰기가 빈번하면서 읽기를 하는데 많은 양의 자원이 소모되는 서비스에 적합하다.

캐시 데이터 전체를 DB에 전송하나 ? 아니면 변경점에 대해서만 DB에 전송하나? 아니면 변경 기록을 기반으로 DB에 전송하나 ? 이는 변경된 데이터에 대해 더티 비트를 설정하며 해결한다.

[https://en.wikipedia.org/wiki/Cache_(computing)](https://en.wikipedia.org/wiki/Cache_%28computing%29)

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/21459dcf-9c30-42e2-aa05-b21e61d90f19/image.png)

[쓰기 전략 - Write Through 패턴]

Write Back 패턴과 같은 원리지만 캐시에 데이터가 입력될 경우 바로 DB와 동기화하는 점이 다르다.

캐시와 DB 데이터가 최신 상태이며, 일관성을 유지한다는 장점이 있다.

그러나 매 요청마다 두 번의 쓰기가 발생하게 되면서 성능 이슈가 발생한다.

불필요한 리소스가 발생한다. 이를 해결하기 위해 TTL(Time to live)을 사용해야 한다.

캐시가 멈출 경우 Write Back 패턴보다 피해 규모는 작겠지만 피할 수 없을거 같다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/ddabc85a-1e3d-4072-b4d2-692348fe9ed1/image.png)

[쓰기 전략 - Write Around 패턴]

쓰기 요청시 데이터를 바로 DB에 저장함. 읽기 요청시 캐시를 읽으며, 캐시에 데이터가 없으면 DB를 읽은 뒤 캐시를 업데이트 함

해당 전략은 속도가 빠르지만, DB에 저장된 데이터가 수정된 뒤, 해당 데이터를 읽을 때 캐시 미스가 나지 않으면 정합성 문제가 발생할 수 있다.

따라서 DB 변경시마다 캐시 또한 변경해야 하며, 캐시의 만료시간을 짧게 조정해야 한다.

https://www.enjoyalgorithms.com/blog/write-around-caching-pattern

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/f171863d-b7ab-4c8c-90d0-98caf3d11659/image.png)

Look Aside + Write Around 조합, Read Through + Write Around 조합, Read Through + Write Through 조합이 사용된다.

## CDN



CDN은 정적 컨텐츠(이미지, 비디오, CSS, JS 파일)를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크다. 정적 컨텐츠를 저장하는 거대한 캐시 서버라고 생각하면 된다.

서비스를 이용하는 과정에서 CDN은 어떤 시점에서 요청을 받지? → 요청이 들어올 경우 CDN을 찌르고, 없으면 로드밸런서를 찌른다?

CDN을 사용할 땐, 다음과 같은 사항을 고려해야 한다.

- CDN는 제3자가 운영하기 떄문에 비용이 발생한다. 자주 사용되지 않는 컨텐츠는 CDN에서 빼도록 하자.
- 적절한 만료 시한을 설정해야 한다. 너무 짧으면 원본 서버에 빈번히 접속해야 하며, 너무 길면 컨텐츠의 신선도가 떨어진다.
- CDN 장애에 대처해야 한다. CDN이 죽었을 경우, 웹사이트가 어떻게 동작해야 하는지 고려해야 한다. 예를 들어 CDN이 작동하지 않는 경우, 해당 문제를 감지하여 원본 서버에서 컨텐츠를 가져오도록 구성하는 방법이 있다.
- 컨텐츠가 만료되지 않아도 제거할 수 있는 방법이 필요하다. URL을 변형하는 방식을 이용한다.

다음은 CDN이 추가된 설계다. 

기존 그림에서는 정적 컨텐츠를 웹 계층에서 가져오는데, 이를 CDN이 대체하게 됐다. 그런데, DB 데이터와 같은 동적 컨텐츠를 들고 오려면 웹 계층을 지나쳐야 하는데, 결국 CDN을 둔다 해도 동적 컨텐츠 조회 때문에 성능 병목이 생기지 않을까? → 정적 컨텐츠 조회가 동적 컨텐츠 조회보다 느린 경우에서 CDN을 이용해 정적 컨텐츠 조회 속도를 줄일 수 있기 떄문에 성능적 이득을 취할 수 있다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/9b7f6ef3-067e-4bc9-b3b0-81ab3ebfaaf9/image.png)

## 무상태 웹 계층



웹 계층의 수평적 확장을 고민해보자. 이를 위해서는 상태 정보를 웹 계층에서 제거해야 한다. 이를 무상태 웹 계층이라고 부른다.(상태 정보는 DB에 저장하자)

상태 정보를 보관하는 서버는 사용자의 정보를 유지하여 요청들 사이에 공유되도록 한다.(예를 들어, 특정 사이트를 로그인한 뒤 이용하는 과정에서 로그인이 유지되는 현상) 

이는 여러 서버를 이용할 경우, 특정 서버에 특정 사용자가 의존된다는 단점이 있다.(서버 1에 로그인한 사용자 A가 서비스 이용 중, 서버 2를 할당받은 경우 로그인이 풀린다) 이는 로드밸런서에 부담을 주며, 로드밸런서 뒷단에 서버를 관리하기도 어려워진다.

이를 해결하기 위해선 무상태 아키텍쳐가 필요하다. 웹 서버는 상태 저장에 대한 책임을 공유 저장소에게 맡긴다. 이런 구조는 단순하고, 안정적이며, 규모 확장이 쉽다.

해당 그림에서 1) 자동 규모 확장은 트래픽의 크기에 따라 동적으로 변경할 수 있다.

기존엔 사용자 정보를 웹 서버 내부에 저장했나?

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/959c971a-3fa2-40fb-85f5-0528ba3c7f59/image.png)

## 데이터 센터



데이터 센터를 이용해 가까운 사용자에게 더욱 빠른 서비스를 제공할 수 있다. 또한, 가용성을 늘려준다.

하지만 다중 데이터 센터 아키텍쳐를 구축하려면 다음과 같은 기술적 문제를 해결해야 한다.

- 트래픽 우회 : 올바른 데이터 센터로 트래픽을 보내는 방법을 찾아야 한다.
- 데이터 동기화 : 데이터 센터마다 데이터베이스 내용이 미묘하게 다를 수 있다. 이를 동기화하는 방법을 구축해야 한다. 데이터를 여러 데이터센터에 걸쳐 다중화하는 방법이 있다.

하단 그림에서 하나의 로드밸런서만 이용하는건가? 대규모 서비스에선 어떻게 작동하지?

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/301f652f-e315-40ef-ac1c-29a843048fd0/image.png)

## 메시지 큐



메시지 큐는 메시지의 무손실(메시지 큐에 보관된 메시지는 소비자가 꺼낼 때 까지 안전하다)을 보장하는, 비동기 통신을 지원하는 컴포넌트다. 메시지의 버퍼 역할을 하며, 비동기적으로 전송한다.

메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다. 소비자 혹은 생산자가 삐꾸나도 메시지를 발행, 수신할 수 있다.

사진 보정 서비스를 만든다고 했을 때, 사진 보정 요청과 사진 보정 작업을 나눈 뒤, 보정 작업 큐를 이용하면 비동기적으로 처리할 수 있다. 보정을 요청할 경우, 이를 메시지 큐에 입력하고, 사진 보정 작업 프로세스들은 요청 사항을 큐에서 받아 비동기적으로 완료한다.

이를 이용하면, 생산자와 소비자 서비스의 규모를 독립적으로 확장할 수 있다. 

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/a1ca60ca-0c70-401d-8b9b-9f5423898667/image.png)

## 로그, 메트릭 그리고 자동화



로그, 메트릭, 자동화는 확장되는 서비스에서 중요한 역할을 맡는다. 특히 로그는 단일 서비스로 모아주는 도구를 활용하면 편리한데, 이를 메시지 큐로 해결할 수 있다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/f913a320-1c50-4ad0-8310-2f88c7a84f65/image.png)

## 데이터베이스 규모 확장



### 수직적 확장

서버에 고성능의 자원을 증설하는 방법이다. 이는 다음과 같은 한계점을 가진다.

- 무한 증설 불가
- SPOF 문제(문제 생기면 전체 다운)
- 비용 문제

### 수평적 확장

샤딩이라고 하며, 더 많은 서버를 추가하는 방법이다.

샤딩은 대규모 데이터베이스를 샤드라고 부르는 작은 단위루 분할하는 기술이다. 모든 샤드는 같은 스키마를 쓰지만 데이터의 중복은 없다.(테이블을 가로로 쪼개는 방법이다. 짝수인 ID와 홀수인 ID를 따로 보관하는 방식)

샤딩 전략에서 가장 중요한 것은 샤딩 키다. 샤딩 키를 기준으로 데이터가 어떻게 분산될지 정해지며, 데이터 조회 및 변경 처리를 효율적으로 할 수 있다.

샤딩을 도입하면 다음과 같은 문제를 해결해야 한다.

- 데이터 재 샤딩 : 하나의 샤드에 들어가는 데이터가 기준을 넘길 경우 재 샤딩이 필요하다. 주로, 절대적인 데이터가 많아져 샤딩이 더 필요한 경우 혹은 데이터 분표가 고르지 못해 특정 샤딩에 많은 데이터가 몰리는 경우 작동한다. 이를 샤드 소진이라고도 부르며, 샤드 키를 계산하는 함수를 재정의 및 데이터를 재배치해야 한다.
- 유명인사 문제 : 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제다. 재 샤딩을 하거나, 특정 키워드에 대해 샤딩을 분리할 수 있다.
- 조인과 비정규화 : 하나의 데이터베이스를 여러 샤드 서버로 쪼개면 데이터 조인이 힘들어진다. 이를 비정규화하거나 하나의 테이블에서 질의가 수행될 수 있도록 해야 한다.

다음은 샤딩을 적용한 아키텍쳐다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/76bd8755-a4a5-4242-a169-f0c60497ea9c/image.png)

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/cb117ef9-b50b-4e0a-b397-e4edc732e565/7c116c74-c942-428f-9a59-5be1d5c1ec6b/image.png)

## 백만 사용자, 그리고 그 이상



- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입. 즉, 여러 대의 서버를 도입
- 가능한 많은 데이터 캐시
- 여러 데이터 센터를 지원
- 정적 컨텐츠는 CDN을 통해 서비스
- 데이터 계층은 샤딩을 통해 확장
- 각 계층은 독립적 서비스로 분할. 메시지 큐를 이용하자
- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용