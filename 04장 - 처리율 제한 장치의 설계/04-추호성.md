# 4. 처리율 제한 장치의 설계
이번 장에서는 처리율 제한 장치에 대해 중점적으로 다뤄볼 예정이다.

- 처리율 제한 장치의 위치

- 처리율 제한 알고리즘(정합성, 자원, 구현 난이도 사이의 트레이드 오프)
- 아키텍쳐의 구체적인 설계와 흐름
- 아키텍쳐의 개선(동시성 처리, 성능 최적화, 모니터링)

<br>

## 1. 문제 이해 및 설계 범위 확정

여러 질문을 통해 다음 내용에 대해 확정해야 한다.

- 처리율 제한 장치를 클라이언트 측에 둘지, 서버 측에 둘지 결정해야 한다.

- 처리 대상에 대한 기준을 정해야 한다.(IP 주소, 사용자 ID 등)
- 시스템 분산 환경을 고려해야 한다.
- 처리율 제한 장치를 하나의 미들웨어로 둘지, 서버 내에 둘지 결정해야 한다.
- 처리율 제한 장치에 얼만큼의 자원을 사용할지 정의해야 한다.(메모리 제한 등)
- 요청이 제한되었을 때, 그 사실을 사용자에게 어떻게 전달할지 결정해야 한다.
- 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주면 안된다. 어떻게 해야 할까

<br>

## 2. 개략적 설계안 제시 및 동의 구하기

다음 질문에 대해 다양한 선택지를 제시하고 각자의 장단점을 고민해보자.

### 처리율 제한 장치는 어디에 둘 것인가?

처리 장치를 클라이언트에 둘 경우, 요청을 쉽게 위변조할 수 있어 보안상 취약하며, 모든 클라이언트의 구현을 통제하기 어렵다는 단점이 있다.

처리 장치를 서버에 둘 경우, 상단에 제시한 단점을 해결할 수 있다. 그러나 구현이 상대적으로 까다롭고(미들웨어에 비해), 서버의 자원을 이용해야 한다는 단점이 있다.

처리 장치를 미들웨어로 둔 뒤, API 서버로 가는 요청을 통제할 수 있다. 위탁 업체를 이용할 수 있기 때문에 이용이 쉽다는 장점이 있다.

기술 스택, 서버의 자원 등 여러 조건이 충족된 경우 + 서버 아키텍쳐가 MSA 기반이며, 사용자 인증과 같은 기능을 처리하기 위해 API 게이트웨이를 이미 설계했다면, 서버에 처리 장치를 두는게 좋다. → 그냥 미들웨어를 이용하자

![image](https://github.com/user-attachments/assets/5f4e0a76-6e15-4f96-9c37-a42fe8181b75)

### 처리율 제한 알고리즘

여러 처리율 제한 알고리즘이 존재하며, 각자의 장단점이 존재한다.

1. 토큰 버킷
    - 버킷을 이용한다. 일정 시간마다 버킷에 토큰이 생성되며, 처리 진행 시 버킷에 토큰을 제거하는 방식이다. 버킷에 토큰이 꽉 찼을 경우 더이상 토큰이 만들어지지 않으며, API 요청 시 토큰이 없는 경우, 해당 요청은 취소된다.

    - 사용자 단위로 버킷이 제공되며, 사용자의 행동이 다양할 경우 여러 버킷이 제공될 수 있다.(예를 들어, 사용자가 접속하기, 리뷰 쓰기, 좋아요 누르기를 할 수 있는 경우, 3개의 버킷이 제공된다)
    - 토큰 버킷 알고리즘은 `버킷 크기`, `초당 토큰 공급량`이라는 2개의 인자를 가진다.
    - 장점 : 구현이 쉬우며, 메모리 사용이 효율적이다. 또한, 트래픽 버스트도 처리할 수 있다.
    - 단점 : 2개의 인자밖에 없어서 적절하게 튜닝하기 어렵다.
    - *“짧은 시간에 집중되는 트래픽(burst of traffic)도 처리 가능하다” 해당 문장이 정확히 어떤 의미를 가지는가? 서버가 터지지 않게 도와준다는 뜻인지, 많은 요청에도 순차적으로 처리해준다는 뜻인지 ? 처리율 제한 알고리즘 자체가 서버가 터지지 않게 도와주는 역할을 하는데 이게 장점인지? 아니면 트래픽 버스트 환경에서 높은 정합성으로 일을 처리한다는 뜻인가 ?*

        ![image](https://github.com/user-attachments/assets/6844daa3-ddfc-49b0-a009-1cfb2d8443b5)

      
2. 누출 버킷
    - 토큰 버킷과 비슷하지만, 요청 처리율이 고정되어 있다는 점이 다르다.

    - 누출 버킷은 버킷에 API 요청들을 쌓아두고, 일정 시간마다 한꺼번에 처리하는 방식을 가진다.(FIFO 방식으로 동작한다) 버킷이 가득 찰 경우에는 새 요청을 버린다.
    - 누출 버킷 알고리즘은 버킷 크기(큐 사이즈), 처리율(단위 시간 처리량) 이라는 2개의 인자를 가진다.
    - 장점 : 큐의 크기가 제한되어 있어 메모리 효율이 좋다. *안정적 출력이 필요한 경우 적합하다?*
    - 단점 : *트래픽 버스트가 있는 경우, 최신 요청들이 버러질 수 있다.(당연한거 아닌가)* 또한, 2개의 인자밖에 없어서 적절하게 튜닝하기 어렵다.
  
        ![image](https://github.com/user-attachments/assets/b4174ddf-e477-4291-9940-a737469c79b5)

3. 고정 윈도우 카운터
    - 타임라인 별로 윈도우를 나누고, 각 윈도우마다 카운터를 두어 처리량을 제한한다.(타임라인 별로 처리량을 제한한다) 처리량을 넘어가는 처리는 버려진다. (타임라인마다 카운터를 초기화한다고 생각하면 된다)

    - 장점 : 메모리 효율이 좋다?(별도의 카운터가 필요해서 안좋을수도), 이해 및 구현이 쉽다.
    - 해당 방식의 가장 큰 단점은, 윈도우 경계에서 기준치를 초과한 트래픽이 발생할 수 있다는 점이다. 타임라인 별 처리량이 5라고 했을 때, 타임 라인이 변하는 시점 이전에 5개의 요청, 변하는 시점 이후에 5개의 요청이 들어온 경우 서버는 순간적으로 10개의 요청을 처리해야 한다.
      
4. 이동 윈도우 로그
    - 고정 윈도우 카운터에 큰 단점을 타임스탬프 추적 방식으로 해결한 알고리즘이다.

    - 작동 방식은 다음과 같다. 새 요청 입력 → 타임스태프에서 이전 타임라인에 존재하는 모든 요청 삭제 → 타임스탬프에 존재하는 요청 크기를 기반으로 새 요청 제한 여부 결정 → 새 요청이 처리됐다면 타임스탬프에 새요청에 대한 로그 추가
    - 장점 : 처리율 한도를무조건 넘지 않는다.
    - 단점 : 타임스탬프에 따로 자원을 투자해야 한다.
5. 이동 윈도 카운터
    - 고정 윈도우 카운터의 문제를 타임스탬프 없이 해결한 알고리즘이다.

    - API 요청이 들어올 경우, 순간 처리량을 실시간으로 계산한 뒤 수용 여부를 판단하는 방식이다.
    - 장점 : 메모리 효율이 좋다. 트래픽 버스트에 잘 대응한다. 특정 시점에서 발생하는 트래픽에 대해 어느정도 잘 대응한다.
    - 단점 : 트래픽 버스트를 완벽하게 대응할 수 없다. 그러나, 심각할 정도로 대응하지 못하는 것은 아니다.

      ![image](https://github.com/user-attachments/assets/62209d0e-58dc-4371-8542-93564a7794c5)

### 개략적인 아키텍쳐

*대상을 어떤 단위로 구분할지에 대해 아직 정하지 않았다*

처리율 제한을 위해선 카운터에 대한 저장이 필요하다. 이는 메모리에 저장하는 것이 유리하다. 일례로 레디스는 INCR, EXPIRE을 이용하여 카운터를 관리한다. INCR은 카운터의 값을 1 올려주며, EXPIRE는 카운터의 타임아웃값을 설정해준다. *자세한 작동 방식은 어떻게 되지?*

처리율 제한 미들웨어는 레디스를 통해 카운터를 확인하며 API 요청에 대해 알맞은 결과를 반환한다.

![image](https://github.com/user-attachments/assets/7b1847b8-99ca-449a-bf1a-f2d05ecb9865)

<br>

## 3. 상세 설계

발생할 수 있는 문제, 각 컴포넌트의 설계 방식을 고민해보고 정책을 구체적으로 정해보자.

### 처리율 제한 규칙

config file을 통해 지정할 수 있다.

처리율 제한 대상, 단위 시간 당 제한 처리 수 등을 지정할 수 있다.

### 처리율 한도 초과 트래픽의 처리

보통은 429 에러를 반환하지만, 한도가 넘어가는 요청을 큐에 보관하여 처리할 수 있다.(기본적으로 처리량이 넘어가는 요청에 대해선 요청을 거절한다) 예를 들어, 주문 시스템, 티켓 예매 등이 있다.

### 처리율 제한 장치가 사용하는 HTTP 헤더

클라이언트는 응답 헤더를 통해 요청에 대한 처리 상태를 확인할 수 있다. 응답 헤더엔 다음과 같은 정보가 포함되어 있다.
- `윈도우 내에 남은 처리 가능 요청 수`

- `매 윈도우마다 클라이언트가 전송할 수 있는 요청의 수`
- `요청 성공을 위해 몇 초 뒤에 요청을 보내야 하는지 알림 정보`

### 상세 설계

- 클라이언트가 요청을 서버에 보내면 요청은 처리율 제한 미들웨어에 도달한다.

- 미들웨어는 제한 규칙을 캐시에서 가져온다. 또한, 카운터와 타임스탬프를 캐시에서 가져온다.
- 해당 값들을 근거로 요청을 수용할지 거절할지 판단한다.
- 요청을 수용할 경우, 요청을 API 서버로 보낸다.
- 요청이 거절된 경우, 429 에러를 클라이언트에 반환한다. 정책에 따라 해당 큐는 메시지 큐에 보관될 수 있다.

![image](https://github.com/user-attachments/assets/0ecfaf93-16f1-4258-a458-4dc63002f2e1)

### 분산 환경에서의 처리율 제한 장치 구현

여러 서버와 병렬 스레드를 구현하는 분산 환경에서는 `경쟁 조건`, `동기화` 문제를 해결해야 한다.

### 경쟁 조건

API 요청이 수용될 때, 메모리에 카운터 값이 증가한다. 이 때, 병행성이 심해 카운터 값이 동시에 증가할 경우 문제가 발생할 수 있다. 이는 락을 이용해 해결할 수 있지만, 락은 시스템의 성능을 저하시킨다. 락 대신 루아 스크립트, 정렬 집합을 이용해보자.

*루아 스크립트와 정렬 집합이 뭐지 ?*

*레디스는 싱글 스레드인데, 경쟁 조건을 생각할 필요가 있을까?*

*싱글 스레드, 멀티 스레드가 구체적으로 뭘까?*

### 동기화 이슈

처리율 제한 장치를 stateless하게 설정하며 저장 책임은 하나의 레디스가 지게 하자.

![image](https://github.com/user-attachments/assets/072a0a3a-0f29-4d03-bfa5-1c118a8bdefd)

### 성능 최적화

사용자가 데이터 센터에서 멀리 떨어져 있다면, 지연 시간으로 인한 성능 저하가 일어날 수 밖에 없다. 이는 에지 서버를 이용하여 해결할 수 있다.(에지 서버의 동기화 문제가 발생할 수 있다)

최종 일관성 모델을 이용하여 해결할 수 있다. *이게 뭐지?*

### 모니터링

처리율 제한 장치를 설치한 후 이를 모니터링하며 작동 추이를 확인해야 한다. 처리율 제한 알고리즘, 처리율 제한 규칙이 효과적인지 확인 가능하다. 

상황과 자원을 모니터링하며 적절한 규칙과 알고리즘을 설정하자. 트래픽이 순간적으로 몰리는 환경에서는 처리율 제한 알고리즘을 변경해야 하며, 처리율 제한 규칙이 빡빡하면 유효 요청이 처리되지 못할 수 있다.

<br>

## 4. 마무리

다음과 같은 부분을 고민해보면 좋다.

- 경성, 연성 처리율 제한

    - 경성 : 요청 개수가 임계치를 절대 넘을 수 없다.

    - 연성 : 요청 개수가 임계치를 잠시 동안은 넘을 수 있다.
- 다양한 계층에서의 처리율 제한
    - OSI 계층을 기반으로 어떤 계층에서 처리율을 제한할 수 있을지 고민해보자

    - *API 서버에도 OSI 계층을 논할 수 있나? 그렇다면 미들웨어는 어떤 계층에 존재하는 것인가? 혹시 우리가 배우고 있는 서버는 애플리케이션 계층에 속하는건가?*
- 처리율 제한을 회피하는 방법. 클라이언트의 설계 방식
    - 클라이언트 캐시를 이용하는 방식

    - 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게 복구될 수 있도록 구현
    - 재시도 로직을 구현할 땐, 충분한 백오프 시간을 둔다.
