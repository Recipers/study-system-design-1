# 13. 검색어 자동완성 시스템

특정 검색어를 입력할 때 마다 자동으로 추천 단어를 기반으로 검색어를 완성해주는 시스템을 만들어보자.

검색어 자동완성 시스템은 실시간성을 정하는게 중요하다. 면접관에게 어떤 시스템을 만드는지 꼭 물어보자.

<br>

## 1. 문제 이해 및 설계 범위 확정

면접관과 대화하며 문제를 이해하고 요구사항을 수립하자

- 검색어의 첫부분을 기반으로 자동완성된다

- 자동완성 검색어는 5개가 표기되며, 이는 질의의 빈도가 기준이다
- 맞춤법 검사를 안하며 단어는 영어 소문자로 한정한다
- DAU는 1000만이다.

다음 조건을 충족해야 한다.

- 빠른 응답 속도가 요구된다. 100밀리초 이하의 반응성을 가져야 한다.

- 연관성이 요구된다. 출력되는 검색어는 입력한 단어와 연관되어야 한다.
- 정렬이 요구된다. 결과는 인기도 등의 순위 모델에 의해 정렬되어 있다.
- 규모 확장성이 요구된다. 시스템이 많은 트래픽을 감당할 수 있어야 한다.
- 고가용성이 요구된다. 시스템의 일부에 장애가 발생할 경우에도 계속 사용될 수 있다.

개략적 규모 추정은 다음과 같다.

- DAU는 1000만명이며, 사용자는 매일 10건의 검색을 수행한다.

- 질의할 때 마다 평균적으로 20 바이트의 데이터를 입력한다.
- 글자를 검색할 때 마다 클라이언트는 요청을 보낸다. 따라서 1000만명 * 10건의 질의 * 20자(한 글자씩 쓸 때 마다 질의를 날린다) / 24시간 / 3600초 = 초당 24000건
- 최대 QPS는 48000건이다.
- 질의 가운데 20%가 신규 검색어라고 가정할 때, 1000만 사용자 * 10 질의 * 20자 * 20% = 0.4GB의 신규 데이터가 매일 추가된다.

<br>

## 2. 개략적 설계안 제시 및 동의 구하기

검색어 자동완성 시스템은 ‘데이터 수집 서비스’와 ‘질의 서비스’로 나뉜다. 

데이터 수집 서비스

- 사용자가 입력한 질의를 실시간으로 수집

- 데이터가 많은 서비스의 실시간 시스템에서는 바람직하지 않음

질의 서비스

- 주어진 질의에 다섯 개의 인기 검색어를 정렬해서 출력

<br>

### 기본적인 데이터 수집 및 질의 서비스

<단어, 검색 횟수>를 저장하는 빈도 테이블을 만든 뒤, 사용자의 검색을 기반으로 갱신하며 SQL의 ORDER BY, Like를 이용하여 인기 검색어를 반환한다.

이는 데이터의 양이 적을 때는 괜찮은데, 양이 많아질 경우 DB 병목 현상이 생길 수 있다.

<br>

## 3. 상세 설계

설계한 서비스를 개선해보자. 다음 부분을 개선하고자 한다.

- 트라이 자료구조 : DB의 저장 방식 변경

- 데이터 수집 서비스
- 질의 서비스
- 규모 확장이 가능한 저장소
- 트라이 연산

<br>

### 트라이 자료구조

트라이 자료구조는 접두어를 기준으로 트리 형태로 단어를 저장하는 구조를 가진다. 하나의 부모에 최대 26개의 자식을 가지며(알파벳 개수) 리프 노드엔 완성된 단어와 검색 빈도수가 저장된다. 

다음은 가장 많이 사용된 질의어 k를 탐색하는 과정과 그 비용이다. 접두어의 길이를 p, 트라이 안에 있는 노드 수를 n, 주어진 노드의 자식 수를 c(해당 서브트리에 존재하는 모든 자식)라고 가정하자.

- 해당 접두어에 대응하는 노드를 찾는데 O(p)의 시간 복잡도를 가진다.

- 해당 노드의 하위 트리에서  모든 유효 노드를 찾는다. 이 때, O(c)의 시간 복잡도를 가진다.
- 유효 노드를 정렬하여 k개의 추천 단어를 찾는다. 이 때, 정렬에 의해 O(clogc)의 시간 복잡도를 가진다.

다음은 be라는 단어에 대해 k개의 인기 검색어를 찾는 과정이다.

1. be를 접두어로 하는 노드를 탐색한다.

2. 하위 트리를 탐색하여 모든 유효 노드를 찾는다.
3. 유효 노드를 정렬한 뒤 출력한다.

이 알고리즘은 직관적이지만 최악의 경우 전체 트리를 전부 검색할 수 있다.(아무 접두어가 없는 경우) 이를 해결하기 위해선 접두어의 최대 길이를 제한하거나 각 노드에 인기 검색어를 캐싱하는 방법이 있다.

<br>

### 접두어의 최대 길이 제한

접두어 노드를 탐색하는 과정이 O(p)이므로, 접두어의 길이가 길어질 경우, 탐색 과정이 길어진다. 따라서, 접두어의 길이를 제한하는 경우 탐색 과정에서의 시간 복잡도가 상수로 변환된다.

<br>

### 노드에 인기 검색어 캐시

각 접두어 노드에 인기 검색어 일부를 캐시하는 방식이다. 캐시에 데이터가 있다면 트리를 탐색할 필요가 없기 때문에 시간 복잡도가 크게 단축된다. 그러나 이는 캐시 저장 공간을 희생한다. 추가적으로, 빠르게 변하는 검색 빈도 환경에서 신선도 문제가 발생할 수 있다.

<br>

### 데이터 수집 서비스

기존 설계안은 사용자가 문자를 타이핑 할 때 마다, 트라이를 수정하는 방식이었다. 이는 매일 입력되는 수천만 건의 질의에 대응하기 때문에, 상당히 느려진다는 단점이 있다. 게다가 인기 검색어가 자주 바뀌지 않으므로 트라이를 자주 갱신할 필요가 없다.(서비스에 따라 다르다)

다음은 데이터 수집 서비스 아키텍쳐다.

로그 취합 서비스(데이터 분석 서비스, 로깅 서비스)에 검색 데이터를 먼저 쌓은 다음, 일정 주기마다 이를 취합하여 트라이 데이터베이스와 캐시를 갱신하는 방식으로 비용을 절감하자.

<br>

### 로그 적재 및 취합 서비스

로그의 경우 양이 많고 데이터 형식이 제각각이기 때문에, 이 데이터를 잘 취합한 뒤 저장해야 한다. 로그는 추가될 뿐 수정되지 않으므로 굳이 인덱스를 걸 필요 없다.

시스템에 따라 다르지만 일주일 간격으로 로그를 (날짜, 단어, 빈도) 방식으로 취합하여 저장한다.

<br>

### 작업 서버

작업서버는 취합한 데이터를 비동기적으로 트라이 데이터베이스에 저장하는 역할을 한다. 작업 서버 여러 대가 병렬적으로 작동할 수 있으려면 NoSQL이 적당할거 같다.

<br>

### 트라이 캐시

트라이 캐시는 분산 캐시 시스템?으로 트라이 데이터를 메모리에 유지하여 연산 성능을 높이는 역할을 한다. 매주 트라이 데이터베이스의 스냅샷을 떠서 갱신한다.

<br>

### 트라이 데이터베이스

트라이 DB는 접두어 노드와 빈도수를 저장하는 역할을 한다. 데이터베이스 형식 선택지는 두 가지 정도 존재한다.

- 문서 저장소 : 주기적으로 트라이를 직렬화하여 DB에 저장할 수 있다. 몽고디비와 같은 문서 저장소를 활용하면 편하게 저장할 수 있다.

- 키-값 저장소 : 접두어를 키값으로, 각 트라이에 보관된 모든 데이터를 값으로 저장한다. 다음은 키-값 저장소의 이용 방식인데, 하나의 접두어에 모든 연관 검색어를 저장하는건가..?

<br>

### 질의 서비스

다음은 질의 서비스에 대한 개선된 설계안이다. 흐름은 다음과 같다.

1. 검색 질의가 로드 밸런서로 전송된다

2. 로드 밸런서는 해당 질의를 API 서버로 보낸다.
3. API 서버는 트라이 캐시를 통해 질의에 대한 응답을 반환한다.
4. 캐시에 데이터가 없는 경우 트라이 DB에서 값을 조회한 뒤, 캐시에 저장 및 반환한다.

추가적으로 다음과 같은 최적화를 진행할 수 있다.

- AJAX 요청 : AJAX 요청을 이용할 경우, 페이지 새로 고침 없이 데이터를 반환 받을 수 있다.

- 브라우저 캐싱 : HTTP 요청은 일차적으로 브라우저 캐시를 탐색해 값을 확인한다. 따라서, 값을 브라우저에 캐싱한다면 같은 요청에 대해 결과를 빠르게 받을 수 있다.
- 데이터 샘플링 : 대규모 시스템에서 모든 질의 결과를 로깅한다면, 엄청난 자원이 낭비될 수 있다. N개의 요청 가운데 1개만 로깅하여 문제를 해결하자.

<br>

### 트라이 연산

트라이 연산이 어떻게 동작하는지 알아보자.

<br>

### 트라이 생성

트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용한다.

<br>

### 트라이 갱신

트라이 갱신에는 두 가지 방법이 있다.

매주 한 번 갱신하는 방법

- 매 주 한 번 새로운 트라이를 만들어 기존 트라이를 대체한다.

트라이의 각 노드를 개별적으로 갱신하는 방법

- 각 노드에 인기 검색어 빈도를 변경할 경우, 그 조상들까지 전부 변경해야 하기 때문에, 큰 트라이에서는 비효율적이다. 작은 트라이에서 사용하도록 하자.

<br>

### 검색어 삭제

금칙어의 경우 자동 완성 결과에서 제외해야 한다. 이는 서버와 트라이 캐시 사이에 필터를 두어 거르도록 하자. 트라이에 이미 금칙어가 있는 경우, 다음 갱신 타임에 삭제하도록 하자

<br>

### 저장소 규모 확장

트라이 자료구조가 커질 경우, 이를 분산해서 저장해야 한다. 단순한 방법으로는 각 첫 알파벳을 기준으로 샤딩하는 방법이 있다. 혹시 크기가 더 커진다면 두 번째 알파벳까지 포함시키는 방법을 이용한다. 

그러나 이는 저장소와 부하 불균형을 야기할 수 있기 때문에, 좋지 않은 방법이다. 이를 해결하기 위해, 과거 질의 데이터 패턴을 분석하여 샤딩하는 방식을 이용하며, 이는 샤드 관리자에 의해 진행된다. 샤드 관리자는 어떤 검색어가 어느 저장소에 저장되어 있는지에 대한 정보를 관리한다. 예를 들어, s로 시작하는 검색어 양이 u~z로 시작하는 검색어 양과 비슷할 경우, u~z 검색을 위한 샤드를 하나만 두어도 된다.

웹 서버는 샤드 관리자 서버로부터 검색어에 대한 샤드 위치를 반환 받고, 이를 바탕으로 샤드에서 데이터를 추출한다. → 샤드 관리자는 캐시로 관리하자

<br>

## 4. 마무리

다음을 추가적으로 고민해보자

- 다국어 지원 : 유니코드로 데이터 저장 및 관리하기
- 국가별로 인기 검색어 순위가 다른 경우 : 국가 별 다른 트라이 만들기 + CDN 붙이기

- 특정 검색어의 인기가 갑자기 높아지는 경우
    - 트라이가 일주일에 한 번 갱신되기 때문에 만든 모델은 실검 반영에 적합하지 않다

    - 심지어 트라이를 구성하는데 너무 많은 시간이 걸린다 → 실시간 반영 불가
    - 샤딩을 통해 작업 대상 데이터의 양을 줄인다
    - 순위 모델을 바꾸어 최근 검색어에 높은 가중치를 주자
    - 데이터가 스트림 형태로 올 수 있어, 모든 데이터를 동시에 사용할 수 없을 수 있다. 이는 특별한 기술이 필요하다.
    - 실시간 검색은 어떻게 구현하는가 ?